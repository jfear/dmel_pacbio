"""PacBio Isoseq workflow.

Runs the Isoseq3 workflow. Our data is from RS II and needs to be converted to be compatible with this workflow.

"""
import pandas as pd
import yaml
from pathlib import Path

from lcdblib.utils.utils import flatten
from lcdblib.snakemake.helpers import fill_patterns

shell.prefix('set -eo pipefail;')
configfile: 'config/config.yaml'
workdir: '.'

sampletable = pd.read_csv(config['sampletable'], sep='\t')
sampletable['data_dir'] = config['data_dir']
sampletable['output_dir'] = config['output_dir']
patterns = yaml.load(open(config['patterns']))
targets = fill_patterns(patterns, sampletable, zip)

localrules: all, cluster_report, classify_report

rule all:
    input:
        flatten(targets['reports']),
        flatten(targets['collapse_isoforms']),


def _bax2bam(wildcards):
    bax_files = Path(config['data_dir'], wildcards.run).glob('*.bax.h5')
    return sorted([x.as_posix() for x in bax_files])


rule bax2bam:
    input:
        movies = _bax2bam
    output:
        flatten(patterns['bax2bam'])
    params:
        prefix = '{output_dir}/{sample}/{run}/{run}'
    log:
        patterns['bax2bam']['subreads']['bam'] + '.log'
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 4,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "bax2bam {input.movies} -o {params.prefix} 2>&1 > {log}"


rule ccs:
    input:
        patterns['bax2bam']['subreads']['bam']
    output:
        flatten(patterns['ccs'])
    params:
        bam = patterns['ccs']['bam'],
        report = patterns['ccs']['report']
    log:
        patterns['ccs']['bam'] + '.log'
    conda:
        'config/pacbio_tools.yaml'
    threads: 28
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 12,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        """
        ccs \
            --maxLength 40000 \
            --minPasses 1 \
            --numThreads {threads} \
            --logFile {log} \
            --reportFile {params.report} \
            --noPolish \
            {input[0]} \
            {params.bam}
        """


rule lima:
    input:
        bam=patterns['ccs']['bam'],
        bc='../data/pacbio_primers.fa'
    output:
        flatten(patterns['lima'])
    params:
        prefix = '{output_dir}/{sample}/{run}/{run}.bam'
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 2,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "lima {input.bam} {input.bc} {params.prefix} --isoseq"


def _isoseq3_merge(wildcards):
    """Merge the different size fractions"""
    sample = wildcards.sample
    curr = sampletable[sampletable['sample'] == sample].copy()
    curr_targets = fill_patterns(patterns['lima'], curr)
    return curr_targets['bam']


rule isoseq3_merge:
    input:
        _isoseq3_merge
    output:
        patterns['merge']['xml']
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 2,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "dataset create --type TranscriptSet {output[0]} {input}"


rule isoseq3_refine:
    input:
        xml = patterns['merge']['xml'],
        bc = '../data/pacbio_primers.fa'
    output:
        flatten(patterns['refine'])
    params:
        bam=patterns['refine']['bam']
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 2,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "isoseq3 refine {input.xml} {input.bc} {params.bam} --require-polya"


rule isoseq3_cluster:
    input:
        patterns['refine']['bam']
    output:
        flatten(patterns['cluster'])
    params:
        bam = patterns['cluster']['bam']
    conda:
        'config/pacbio_tools.yaml'
    threads: 32
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 24,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "isoseq3 cluster {input[0]} {params.bam} -j {threads}"


def _merge_subreads(wildcards):
    """Merge subreads from different size fractions for polishing"""
    sample = wildcards.sample
    curr = sampletable[sampletable['sample'] == sample].copy()
    curr_targets = fill_patterns(patterns['bax2bam'], curr)
    return curr_targets['subreads']['bam']


rule merge_subreads:
    input:
        _merge_subreads
    output:
        patterns['merge_subreads']['xml']
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 2,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "dataset create --type SubreadSet {output[0]} {input}"


rule isoseq3_polish:
    input:
        unpolished = patterns['cluster']['bam'],
        subreads = patterns['merge_subreads']['xml']
    output:
        flatten(patterns['polish'])
    params:
        bam = patterns['polish']['bam']
    conda:
        'config/pacbio_tools.yaml'
    threads: 32
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 12,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "isoseq3 polish {input.unpolished} {input.subreads} {params.bam} -j {threads}"


rule gmap_build:
    input:
        config['fasta']
    output:
        patterns['gmap_ref']
    params:
        '{output_dir}/references/dm6'
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 8,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell:
        "gmap_build -D {wildcards.output_dir}/references -d dm6 {input[0]}"


rule gunzip_fasta:
    input:
        patterns['polish']['hq_fasta']
    output:
        temp(patterns['gunzip']['hq_fasta'])
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell:
        "gunzip -c {input[0]} > {output[0]}"


rule gmap_align:
    """
    Settings based on PacBio suggestions here:
    https://github.com/Magdoll/cDNA_Cupcake/wiki/Best-practice-for-aligning-Iso-Seq-to-reference-genome:-minimap2,-GMAP,-STAR,-BLAT
    """
    input:
        fasta = patterns['gunzip']['hq_fasta'],
        ref = rules.gmap_build.output[0]
    output:
        sam = temp(patterns['gmap_align']['sam']),
        bam = patterns['gmap_align']['bam']
    log:
        patterns['gmap_align']['sam'] + '.log'
    conda:
        'config/pacbio_tools.yaml'
    threads: 32
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 12,
        time_hr = lambda wildcards, attempt: attempt * 4
    shell: """
        gmap \
            -D {wildcards.output_dir}/references \
            -d dm6 \
            -f samse \
            -n 0 \
            -t {threads} \
            --cross-species \
            --max-intronlength-ends 200000 \
            -z sense_force \
            {input.fasta} \
            > {output.sam} \
            2> {log} && \
        samtools view -bS {output.sam} | samtools sort - > {output.bam} && \
        samtools index {output.bam}
    """


def _merge_lima(wildcards):
    """Merge lima clips from different size fractions"""
    sample = wildcards.sample
    curr = sampletable[sampletable['sample'] == sample].copy()
    curr_targets = fill_patterns(patterns['lima'], curr)
    return curr_targets['clips']


rule merge_lima:
    input:
        _merge_lima
    output:
        patterns['merge_lima']['clips']
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell:
        "cat {input} > {output[0]}"


rule classify_report:
    input:
        clips = patterns['merge_lima']['clips'],
        bc = '../data/pacbio_primers.fa',
        flnc = patterns['cluster']['bam']
    output:
        patterns['reports']['classify']
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell: """
        python $CONDA_PREFIX/bin/isoseq3_make_classify_report.py {input.clips} {input.bc} --flnc_bam {input.flnc} && \
        mv classify_report.csv {output[0]}
    """


rule cluster_report:
    input:
        polished = patterns['polish']['bam']
    output:
        patterns['reports']['cluster']
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell: """
        python $CONDA_PREFIX/bin/isoseq3_make_cluster_report.py {input.polished} && \
        mv cluster_report.csv {output[0]}
    """

rule gunzip_fastq:
    input:
        patterns['polish']['hq_fastq']
    output:
        temp(patterns['gunzip']['hq_fastq'])
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell:
        "gunzip -c {input[0]} > {output[0]}"


rule collapse_isoforms:
    input:
        hq_fastq = patterns['gunzip']['hq_fastq'],
        bam = patterns['gmap_align']['bam']
    output:
        flatten(patterns['collapse_isoforms'])
    params:
        prefix = '{output_dir}/{sample}/{sample}'
    conda:
        'config/pacbio_tools.yaml'
    resources:
        mem_gb = lambda wildcards, attempt: attempt * 1,
        time_hr = lambda wildcards, attempt: attempt * 1
    shell: """
        tmp=`mktemp --suffix=.sam` && \
        samtools view -h -F 4 {input.bam} > $tmp && \
        python $CONDA_PREFIX/bin/collapse_isoforms_by_sam.py \
            --input {input.hq_fastq} \
            --fq \
            -s $tmp \
            --dun-merge-5-shorter -o {params.prefix} && \
        rm $tmp
    """


"""Real world example of these steps
$ wget https://downloads.pacbcloud.com/public/dataset/RC0_1cell_2017/m54086_170204_081430.subreads.bam
$ wget https://downloads.pacbcloud.com/public/dataset/RC0_1cell_2017/m54086_170204_081430.subreads.bam.pbi
$ wget https://downloads.pacbcloud.com/public/dataset/RC0_1cell_2017/m54086_170204_081430.subreadset.xml

$ ccs --version
ccs 3.1.0 (commit v3.1.0)

$ ccs m54086_170204_081430.subreads.bam m54086_170204_081430.ccs.bam \
      --noPolish --minPasses 1 --maxPoaCoverage 10

$ cat primers.fasta
>primer_5p
AAGCAGTGGTATCAACGCAGAGTACATGGGG
>primer_3p
AAGCAGTGGTATCAACGCAGAGTAC

$ lima --version
lima 1.8.0 (commit v1.8.0)

$ lima m54086_170204_081430.ccs.bam primers.fasta m54086_170204_081430.fl.bam \
       --isoseq --no-pbi

$ ls m54086_170204_081430.fl*
m54086_170204_081430.fl.json         m54086_170204_081430.fl.lima.summary
m54086_170204_081430.fl.lima.clips   m54086_170204_081430.fl.primer_5p--primer_3p.bam
m54086_170204_081430.fl.lima.counts  m54086_170204_081430.fl.primer_5p--primer_3p.subreadset.xml
m54086_170204_081430.fl.lima.report

$ isoseq3 refine m54086_170204_081430.fl.primer_5p--primer_3p.bam primers.fasta m54086_170204_081430.flnc.bam

$ ls m54086_170204_081430.flnc.*
m54086_170204_081430.flnc.bam                   m54086_170204_081430.flnc.filter_summary.json
m54086_170204_081430.flnc.bam.pbi               m54086_170204_081430.flnc.report.csv
m54086_170204_081430.flnc.consensusreadset.xml

$ isoseq3 cluster m54086_170204_081430.flnc.bam unpolished.bam --verbose
Read BAM                 : (197791) 4s 20ms
Convert to reads         : 1s 431ms
Sort Reads               : 56ms 947us
Aligning Linear          : 2m 5s
Read to clusters         : 9s 432ms
Aligning Linear          : 54s 288ms
Merge by mapping         : 36s 138ms
Consensus                : 30s 126ms
Merge by mapping         : 5s 418ms
Consensus                : 3s 597ms
Write output             : 1s 134ms
Complete run time        : 4m 32s

$ ls unpolished*
unpolished.bam  unpolished.bam.pbi  unpolished.cluster  unpolished.fasta  unpolished.transcriptset.xml

$ isoseq3 polish unpolished.bam m54086_170204_081430.subreadset.xml polished.bam --verbose
14561

$ ls polished*
polished.bam                 polished.hq.fastq.gz
polished.bam.pbi             polished.lq.fasta.gz
polished.cluster_report.csv  polished.lq.fastq.gz
polished.hq.fasta.gz         polished.transcriptset.xml

"""
